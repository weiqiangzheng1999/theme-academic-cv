---
title: Accelerated Algorithms for Constrained Nonconvex-Nonconcave Min-Max Optimization and Comonotone Inclusion
authors:
- Yang Cai
- Argyris Oikonomou
- Weiqiang Zheng
date: '2022-08-01'
publishDate: '2022-08-01'
publication_types:
- manuscript
publication: 'Working Paper. NeurIPS 2022 OPT Workshop'
abstract: We study constrained comonotone min-max optimization, a structured class of nonconvex-nonconcave min-max optimization problems, and their generalization to comonotone inclusion. In our first contribution, we extend the Extra Anchored Gradient (EAG) algorithm, originally proposed by Yoon and Ryu (2021) for unconstrained min-max optimization, to constrained comonotone min-max optimization and comonotone inclusion, achieving an optimal convergence rate of {{< math >}}$ O(\frac{1}{T}) ${{< /math >}} among all first-order methods. Additionally, we prove that the algorithm's iterations converge to a point in the solution set. In our second contribution, we extend the Fast Extra Gradient (FEG) algorithm, as developed by Lee and Kim (2021), to constrained comonotone min-max optimization and comonotone inclusion, achieving the same {{< math >}}$ O(\frac{1}{T}) ${{< /math >}} convergence rate. This rate is applicable to the broadest set of comonotone inclusion problems yet studied in the literature. Our analyses are based on simple potential function arguments, which might be useful for analyzing other accelerated algorithms.

tags:
- Computer Science - Data Structures and Algorithms
- Computer Science - Machine Learning
- Mathematics - Optimization and Control
links:
- name: arXiv
  url: http://arxiv.org/abs/2206.05248
---
