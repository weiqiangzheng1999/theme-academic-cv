@inproceedings{cai_doubly_2023,
 abstract = {We consider online learning in multi-player smooth monotone games. Existing algorithms have limitations such as (1) being only applicable to strongly monotone games; (2) lacking the no-regret guarantee; (3) having only asymptotic or slow (1𝑇√)O(1T)\mathcal\O\(\frac\1\\\sqrt\T\\) last-iterate convergence rate to a Nash equilibrium. While the (1𝑇√)O(1T)\mathcal\O\(\frac\1\\\sqrt\T\\) rate is tight for a large class of algorithms including the well-studied extragradient algorithm and optimistic gradient algorithm, it is not optimal for all gradient-based algorithms. We propose the accelerated optimistic gradient (AOG) algorithm, the first doubly optimal no-regret learning algorithm for smooth monotone games. Namely, our algorithm achieves both (i) the optimal (𝑇‾‾√)O(T)\mathcal\O\(\sqrt\T\) regret in the adversarial setting under smooth and convex loss functions and (ii) the optimal (1𝑇)O(1T)\mathcal\O\(\frac\1\\T\) last-iterate convergence rate to a Nash equilibrium in multi-player smooth monotone games. As a byproduct of the accelerated last-iterate convergence rate, we further show that each player suffers only an (log𝑇)O(log⁡T)\mathcal\O\(\log T) individual worst-case dynamic regret, providing an exponential improvement over the previous state-of-the-art (𝑇‾‾√)O(T)\mathcal\O\(\sqrt\T\) bound.},
 author = {Cai, Yang and Zheng, Weiqiang},
 booktitle = {Proceedings of the 40th International Conference on Machine Learning},
 file = {Full Text PDF:files/690/Cai 和 Zheng - 2023 - Doubly Optimal No-Regret Learning in Monotone Game.pdf:application/pdf},
 language = {en},
 month = {July},
 note = {ISSN: 2640-3498},
 pages = {3507--3524},
 publisher = {PMLR},
 title = {Doubly Optimal No-Regret Learning in Monotone Games},
 url = {https://proceedings.mlr.press/v202/cai23g.html},
 urldate = {2023-11-26},
 year = {2023}
}
