---
title: Doubly Optimal No-Regret Learning in Monotone Games
authors:
- Yang Cai
- Weiqiang Zheng
date: '2023-07-01'
publishDate: '2023-11-26T02:45:28.699142Z'
publication_types:
- paper-conference
publication: '*Proceedings of the 40th International Conference on Machine Learning*'
abstract: We consider online learning in multi-player smooth monotone games. Existing
  algorithms have limitations such as (1) being only applicable to strongly monotone
  games; (2) lacking the no-regret guarantee; (3) having only asymptotic or slow îˆ»(1ğ‘‡âˆš)O(1T)mathcalO(frac1sqrtT)
  last-iterate convergence rate to a Nash equilibrium. While the îˆ»(1ğ‘‡âˆš)O(1T)mathcalO(frac1sqrtT)
  rate is tight for a large class of algorithms including the well-studied extragradient
  algorithm and optimistic gradient algorithm, it is not optimal for all gradient-based
  algorithms. We propose the accelerated optimistic gradient (AOG) algorithm, the
  first doubly optimal no-regret learning algorithm for smooth monotone games. Namely,
  our algorithm achieves both (i) the optimal îˆ»(ğ‘‡â€¾â€¾âˆš)O(T)mathcalO(sqrtT) regret in
  the adversarial setting under smooth and convex loss functions and (ii) the optimal
  îˆ»(1ğ‘‡)O(1T)mathcalO(frac1T) last-iterate convergence rate to a Nash equilibrium in
  multi-player smooth monotone games. As a byproduct of the accelerated last-iterate
  convergence rate, we further show that each player suffers only an îˆ»(logğ‘‡)O(logâ¡T)mathcalO(log
  T) individual worst-case dynamic regret, providing an exponential improvement over
  the previous state-of-the-art îˆ»(ğ‘‡â€¾â€¾âˆš)O(T)mathcalO(sqrtT) bound.
links:
- name: URL
  url: https://proceedings.mlr.press/v202/cai23g.html
---
