---
title: Finite-Time Last-Iterate Convergence for Learning in Multi-Player Games
authors:
- Yang Cai
- Argyris Oikonomou
- Weiqiang Zheng
date: '2022-11-01'
publishDate: '2023-11-26T02:45:28.713498Z'
publication_types:
- paper-conference
publication: 'The Thirty-Sixth Annual Conference on Neural Information Processing Systems (NeurIPS 2022 **Oral Presentation**)'
abstract: We study the question of last-iterate convergence rate of the extragradient
  algorithm by Korpelevich [1976] and the optimistic gradient algorithm by Popov [1980]
  in multi-player games. We show that both algorithms with constant step-size have
  last-iterate convergence rate of {{< math >}}$ O(\frac{1}{\sqrt{T}}) ${{< /math >}} to a Nash equilibrium in terms
  of the gap function in smooth monotone games, where each player's action set is
  an arbitrary convex set. Previous results only study the unconstrained setting,
  where each player's action set is the entire Euclidean space. Our results address
  an open question raised in several recent work by Hsieh et al. [2019], Golowich
  et al. [2020a,b], who ask for last-iterate convergence rate of either the extragradient
  or the optimistic gradient algorithm in the constrained setting. Our convergence
  rates for both algorithms are tight and match the lower bounds by Golowich et al.
  [2020a,b]. At the core of our results lies a new notion -- the tangent residual,
  which we use to measure the proximity to equilibrium. We use the tangent residual
  (or a slight variation of the tangent residual) as the the potential function in
  our analysis of the extragradient algorithm (or the optimistic gradient algorithm)
  and prove that it is non-increasing between two consecutive iterates.
links:
- name: video
  url: https://www.youtube.com/watch?v=cFYABnzjvJI&t=1s&ab_channel=SimonsInstitute
- name: openreivew
  url: https://openreview.net/forum?id=snUOkDdJypm
---
