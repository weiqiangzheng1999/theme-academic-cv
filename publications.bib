
@inproceedings{cai_uncoupled_2023,
	title = {Uncoupled and {Convergent} {Learning} in {Two}-{Player} {Zero}-{Sum} {Markov} {Games} with {Bandit} {Feedback}},
	url = {http://arxiv.org/abs/2303.02738},
	doi = {10.48550/arXiv.2303.02738},
	abstract = {We revisit the problem of learning in two-player zero-sum Markov games, focusing on developing an algorithm that is uncoupled, convergent, and rational, with non-asymptotic convergence rates. We start from the case of stateless matrix game with bandit feedback as a warm-up, showing an \$O(t{\textasciicircum}\{-{\textbackslash}frac\{1\}\{8\}\})\$ last-iterate convergence rate. To the best of our knowledge, this is the first result that obtains finite last-iterate convergence rate given access to only bandit feedback. We extend our result to the case of irreducible Markov games, providing a last-iterate convergence rate of \$O(t{\textasciicircum}\{-{\textbackslash}frac\{1\}\{9+{\textbackslash}varepsilon\}\})\$ for any \${\textbackslash}varepsilon{\textgreater}0\$. Finally, we study Markov games without any assumptions on the dynamics, and show a path convergence rate, which is a new notion of convergence we defined, of \$O(t{\textasciicircum}\{-{\textbackslash}frac\{1\}\{10\}\})\$. Our algorithm removes the coordination and prior knowledge requirement of [Wei et al., 2021], which pursued the same goals as us for irreducible Markov games. Our algorithm is related to [Chen et al., 2021, Cen et al., 2021] and also builds on the entropy regularization technique. However, we remove their requirement of communications on the entropy values, making our algorithm entirely uncoupled.},
	urldate = {2023-11-12},
	publisher = {arXiv},
	author = {Cai, Yang and Luo, Haipeng and Wei, Chen-Yu and Zheng, Weiqiang},
	month = nov,
	year = {2023},
	note = {arXiv:2303.02738 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:files/676/Cai Á≠â - 2023 - Uncoupled and Convergent Learning in Two-Player Ze.pdf:application/pdf;arXiv.org Snapshot:files/677/2303.html:text/html},
}

@inproceedings{cai_accelerated_2022,
	title = {Accelerated {Single}-{Call} {Methods} for {Constrained} {Min}-{Max} {Optimization}},
	url = {https://openreview.net/forum?id=HRwN7IQLUKA},
	abstract = {We study first-order methods for constrained min-max optimization. Existing methods either require two gradient calls or two projections in each iteration, which may be costly in some applications. In this paper, we first show that a variant of the {\textbackslash}emph\{Optimistic Gradient (OG)\} method, a {\textbackslash}emph\{single-call single-projection\} algorithm, has \$O({\textbackslash}frac\{1\}\{{\textbackslash}sqrt\{T\}\})\$ best-iterate convergence rate for inclusion problems with operators that satisfy the weak Minty variation inequality (MVI). Our second result is the first single-call single-projection algorithm -- the {\textbackslash}emph\{Accelerated Reflected Gradient (ARG)\} method that achieves the {\textbackslash}emph\{optimal \$O({\textbackslash}frac\{1\}\{T\})\$\} last-iterate convergence rate for inclusion problems that satisfy negative comonotonicity. Both the weak MVI and negative comonotonicity are well-studied assumptions and capture a rich set of non-convex non-concave min-max optimization problems. Finally, we show that the {\textbackslash}emph\{Reflected Gradient (RG)\} method, another {\textbackslash}emph\{single-call single-projection\} algorithm, has \$O({\textbackslash}frac\{1\}\{{\textbackslash}sqrt\{T\}\})\$ last-iterate convergence rate for constrained convex-concave min-max optimization, answering an open problem of [Hsieh et al., 2019]. Our convergence rates hold for standard measures such as the tangent residual and the natural residual.},
	language = {en},
	urldate = {2023-11-26},
	author = {Cai, Yang and Zheng, Weiqiang},
	month = sep,
	year = {2022},
	file = {Full Text PDF:files/686/Cai Âíå Zheng - 2022 - Accelerated Single-Call Methods for Constrained Mi.pdf:application/pdf},
}

@inproceedings{cai_doubly_2023,
	title = {Doubly {Optimal} {No}-{Regret} {Learning} in {Monotone} {Games}},
	url = {https://proceedings.mlr.press/v202/cai23g.html},
	abstract = {We consider online learning in multi-player smooth monotone games. Existing algorithms have limitations such as (1) being only applicable to strongly monotone games; (2) lacking the no-regret guarantee; (3) having only asymptotic or slow Óàª(1ùëá‚àö)O(1T){\textbackslash}mathcal\{O\}({\textbackslash}frac\{1\}\{{\textbackslash}sqrt\{T\}\}) last-iterate convergence rate to a Nash equilibrium. While the Óàª(1ùëá‚àö)O(1T){\textbackslash}mathcal\{O\}({\textbackslash}frac\{1\}\{{\textbackslash}sqrt\{T\}\}) rate is tight for a large class of algorithms including the well-studied extragradient algorithm and optimistic gradient algorithm, it is not optimal for all gradient-based algorithms. We propose the accelerated optimistic gradient (AOG) algorithm, the first doubly optimal no-regret learning algorithm for smooth monotone games. Namely, our algorithm achieves both (i) the optimal Óàª(ùëá‚Äæ‚Äæ‚àö)O(T){\textbackslash}mathcal\{O\}({\textbackslash}sqrt\{T\}) regret in the adversarial setting under smooth and convex loss functions and (ii) the optimal Óàª(1ùëá)O(1T){\textbackslash}mathcal\{O\}({\textbackslash}frac\{1\}\{T\}) last-iterate convergence rate to a Nash equilibrium in multi-player smooth monotone games. As a byproduct of the accelerated last-iterate convergence rate, we further show that each player suffers only an Óàª(logùëá)O(log‚Å°T){\textbackslash}mathcal\{O\}({\textbackslash}log T) individual worst-case dynamic regret, providing an exponential improvement over the previous state-of-the-art Óàª(ùëá‚Äæ‚Äæ‚àö)O(T){\textbackslash}mathcal\{O\}({\textbackslash}sqrt\{T\}) bound.},
	language = {en},
	urldate = {2023-11-26},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Cai, Yang and Zheng, Weiqiang},
	month = jul,
	year = {2023},
	note = {ISSN: 2640-3498},
	pages = {3507--3524},
	file = {Full Text PDF:files/690/Cai Âíå Zheng - 2023 - Doubly Optimal No-Regret Learning in Monotone Game.pdf:application/pdf},
}

@inproceedings{xia_beyond_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Beyond the¬†{Worst} {Case}: {Semi}-random {Complexity} {Analysis} of¬†{Winner} {Determination}},
	isbn = {978-3-031-22832-2},
	shorttitle = {Beyond the¬†{Worst} {Case}},
	doi = {10.1007/978-3-031-22832-2_19},
	abstract = {The computational complexity of winner determination is a classical and important problem in computational social choice. Previous work based on worst-case analysis has established NP-hardness of winner determination for some classic voting rules, such as Kemeny, Dodgson, and Young.},
	language = {en},
	booktitle = {Web and {Internet} {Economics}},
	publisher = {Springer International Publishing},
	author = {Xia, Lirong and Zheng, Weiqiang},
	editor = {Hansen, Kristoffer Arnsfelt and Liu, Tracy Xiao and Malekian, Azarakhsh},
	year = {2022},
	keywords = {Computational social choice, Semi-random complexity, Winner determination},
	pages = {330--347},
	file = {Full Text PDF:files/692/Xia Âíå Zheng - 2022 - Beyond the¬†Worst Case Semi-random Complexity Anal.pdf:application/pdf},
}

@inproceedings{cai_finite-time_2022,
	title = {Finite-{Time} {Last}-{Iterate} {Convergence} for {Learning} in {Multi}-{Player} {Games}},
	url = {https://openreview.net/forum?id=snUOkDdJypm},
	abstract = {We study the question of last-iterate convergence rate of the extragradient algorithm by Korpelevich [1976] and the optimistic gradient algorithm by Popov [1980] in multi-player games. We show that both algorithms with constant step-size have last-iterate convergence rate of \$O({\textbackslash}frac\{1\}\{{\textbackslash}sqrt\{T\}\})\$ to a Nash equilibrium in terms of the gap function in smooth monotone games, where each player's action set is an arbitrary convex set. Previous results only study the unconstrained setting, where each player's action set is the entire Euclidean space. Our results address an open question raised in several recent work by Hsieh et al. [2019], Golowich et al. [2020a,b], who ask for last-iterate convergence rate of either the extragradient or the optimistic gradient algorithm in the constrained setting. Our convergence rates for both algorithms are tight and match the lower bounds by Golowich et al. [2020a,b]. At the core of our results lies a new notion -- the tangent residual, which we use to measure the proximity to equilibrium. We use the tangent residual (or a slight variation of the tangent residual) as the the potential function in our analysis of the extragradient algorithm (or the optimistic gradient algorithm) and prove that it is non-increasing between two consecutive iterates.},
	language = {en},
	urldate = {2023-11-26},
	author = {Cai, Yang and Oikonomou, Argyris and Zheng, Weiqiang},
	month = may,
	year = {2022},
	file = {Full Text PDF:files/694/Cai Á≠â - 2022 - Finite-Time Last-Iterate Convergence for Learning .pdf:application/pdf},
}

@misc{cai_accelerated_2022-1,
	title = {Accelerated {Algorithms} for {Monotone} {Inclusion} and {Constrained} {Nonconvex}-{Nonconcave} {Min}-{Max} {Optimization}},
	url = {http://arxiv.org/abs/2206.05248},
	doi = {10.48550/arXiv.2206.05248},
	abstract = {We study monotone inclusions and monotone variational inequalities, as well as their generalizations to non-monotone settings. We first show that the Extra Anchored Gradient (EAG) algorithm, originally proposed by Yoon and Ryu [2021] for unconstrained convex-concave min-max optimization, can be applied to solve the more general problem of Lipschitz monotone inclusion. More specifically, we prove that the EAG solves Lipschitz monotone inclusion problems with an accelerated convergence rate of \$O({\textbackslash}frac\{1\}\{T\})\$, which is optimal among all first-order methods [Diakonikolas, 2020, Yoon and Ryu, 2021]. Our second result is an accelerated forward-backward splitting algorithm (AS), which not only achieves the accelerated \$O({\textbackslash}frac\{1\}\{T\})\$ convergence rate for all monotone inclusion problems, but also exhibits the same accelerated rate for a family of general (non-monotone) inclusion problems that concern negative comonotone operators. As a special case of our second result, AS enjoys the \$O({\textbackslash}frac\{1\}\{T\})\$ convergence rate for solving a non-trivial class of nonconvex-nonconcave min-max optimization problems. Our analyses are based on simple potential function arguments, which might be useful for analysing other accelerated algorithms.},
	urldate = {2023-11-26},
	publisher = {arXiv},
	author = {Cai, Yang and Oikonomou, Argyris and Zheng, Weiqiang},
	month = aug,
	year = {2022},
	note = {arXiv:2206.05248 [cs, math]},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:files/697/Cai Á≠â - 2022 - Accelerated Algorithms for Monotone Inclusion and .pdf:application/pdf;arXiv.org Snapshot:files/700/2206.html:text/html},
}

@misc{cai_tight_2022,
	title = {Tight {Last}-{Iterate} {Convergence} of the {Extragradient} and the {Optimistic} {Gradient} {Descent}-{Ascent} {Algorithm} for {Constrained} {Monotone} {Variational} {Inequalities}},
	url = {http://arxiv.org/abs/2204.09228},
	doi = {10.48550/arXiv.2204.09228},
	abstract = {The monotone variational inequality is a central problem in mathematical programming that unifies and generalizes many important settings such as smooth convex optimization, two-player zero-sum games, convex-concave saddle point problems, etc. The extragradient algorithm by Korpelevich [1976] and the optimistic gradient descent-ascent algorithm by Popov [1980] are arguably the two most classical and popular methods for solving monotone variational inequalities. Despite their long histories, the following major problem remains open. What is the last-iterate convergence rate of the extragradient algorithm or the optimistic gradient descent-ascent algorithm for monotone and Lipschitz variational inequalities with constraints? We resolve this open problem by showing that both the extragradient algorithm and the optimistic gradient descent-ascent algorithm have a tight \$O{\textbackslash}left({\textbackslash}frac\{1\}\{{\textbackslash}sqrt\{T\}\}{\textbackslash}right)\$ last-iterate convergence rate for arbitrary convex feasible sets, which matches the lower bound by Golowich et al. [2020a,b]. Our rate is measured in terms of the standard gap function. At the core of our results lies a non-standard performance measure -- the tangent residual, which can be viewed as an adaptation of the norm of the operator that takes the local constraints into account. We use the tangent residual (or a slight variation of the tangent residual) as the the potential function in our analysis of the extragradient algorithm (or the optimistic gradient descent-ascent algorithm) and prove that it is non-increasing between two consecutive iterates.},
	urldate = {2023-11-26},
	publisher = {arXiv},
	author = {Cai, Yang and Oikonomou, Argyris and Zheng, Weiqiang},
	month = may,
	year = {2022},
	note = {arXiv:2204.09228 [cs, math]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:files/701/Cai Á≠â - 2022 - Tight Last-Iterate Convergence of the Extragradien.pdf:application/pdf;arXiv.org Snapshot:files/704/2204.html:text/html},
}

@inproceedings{deng_nash_2022,
	address = {New York, NY, USA},
	series = {{WWW} '22},
	title = {Nash {Convergence} of {Mean}-{Based} {Learning} {Algorithms} in {First} {Price} {Auctions}},
	isbn = {978-1-4503-9096-5},
	url = {https://dl.acm.org/doi/10.1145/3485447.3512059},
	doi = {10.1145/3485447.3512059},
	abstract = {Understanding the convergence properties of learning dynamics in repeated auctions is a timely and important question in the area of learning in auctions, with numerous applications in, e.g., online advertising markets. This work focuses on repeated first price auctions where bidders with fixed values for the item learn to bid using mean-based algorithms ‚Äì a large class of online learning algorithms that include popular no-regret algorithms such as Multiplicative Weights Update and Follow the Perturbed Leader. We completely characterize the learning dynamics of mean-based algorithms, in terms of convergence to a Nash equilibrium of the auction, in two senses: (1) time-average: the fraction of rounds where bidders play a Nash equilibrium approaches 1 in the limit; (2) last-iterate: the mixed strategy profile of bidders approaches a Nash equilibrium in the limit. Specifically, the results depend on the number of bidders with the highest value: Our discovery opens up new possibilities in the study of convergence dynamics of learning algorithms.},
	urldate = {2023-11-25},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2022},
	publisher = {Association for Computing Machinery},
	author = {Deng, Xiaotie and Hu, Xinyan and Lin, Tao and Zheng, Weiqiang},
	month = apr,
	year = {2022},
	keywords = {first price auctions, mean-based algorithms, online learning},
	pages = {141--150},
	file = {Full Text PDF:files/703/Deng Á≠â - 2022 - Nash Convergence of Mean-Based Learning Algorithms.pdf:application/pdf},
}

@inproceedings{ran_revenue_2022,
	address = {Richland, SC},
	series = {{AAMAS} '22},
	title = {Revenue and {User} {Traffic} {Maximization} in {Mobile} {Short}-{Video} {Advertising}},
	isbn = {978-1-4503-9213-6},
	abstract = {A new mobile attention economy has emerged with the explosive growth of short-video apps such as TikTok. In this internet market, three types of agents interact with each other: the platform, influencers, and advertisers. A short-video platform encourages its influencers to attract users by creating appealing content through short-form videos and allows advertisers to display their ads in short-form videos. There are two options for the advertisers: one is to bid for platform advert slots in a similar way to search engine auctions; the other is to pay an influencer to make engaging short videos and promote them through the influencer's channel. The second option will generate a higher conversion ratio if advertisers choose the right influencers whose followers match their target market. Although displaying influencer ads will generate less revenue, it is more engaging than platform ads, which is better for maintaining user traffic. Therefore, it is crucial for a platform to balance these factors by establishing a sustainable business agreement with its influencers and advertisers. In this paper, we develop a two-stage solution for a platform to maximize short-term revenue and long-term user traffic maintenance. In the first stage, we estimate the impact of user traffic generated by displaying influencer ads and characterize the user traffic the platform should allocate to influencers for overall revenue maximization. In the second stage, we devise an optimal (1-1/e)-competitive algorithm for ad slot allocation. To complement this analysis, we examine the ratio of the revenue generated by our online algorithm to the optimal offline revenue. Our simulation results show that this ratio is 0.94 on average, which is much higher than (1-1/e) and outperforms four baseline algorithms.},
	urldate = {2023-11-25},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Ran, Dezhi and Zheng, Weiqiang and Li, Yunqi and Bian, Kaigui and Zhang, Jie and Deng, Xiaotie},
	month = may,
	year = {2022},
	keywords = {competitive ratio, revenue maximization, short-video advertising},
	pages = {1092--1100},
	file = {Full Text PDF:files/706/Ran Á≠â - 2022 - Revenue and User Traffic Maximization in Mobile Sh.pdf:application/pdf},
}

@article{xia_smoothed_2021,
	title = {The {Smoothed} {Complexity} of {Computing} {Kemeny} and {Slater} {Rankings}},
	volume = {35},
	copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/16720},
	doi = {10.1609/aaai.v35i6.16720},
	abstract = {The computational complexity of winner determination under common voting rules is a classical and fundamental topic in the field of computational social choice. Previous work has established the NP-hardness of winner determination under some commonly-studied voting rules, such as the Kemeny rule and the Slater rule. In a recent position paper, Baumeister, Hogrebe, and Rothe (2020) questioned the relevance of the worst-case nature of NP-hardness in social choice and proposed to conduct smoothed complexity analysis (Spielman and Teng 2009) under Blaser and Manthey‚Äôs (2015) framework.


In this paper, we develop the first smoothed complexity results for winner determination in voting. We prove the smoothed hardness of Kemeny and Slater using the classical smoothed runtime analysis, and prove a parameterized typical-case smoothed easiness result for Kemeny. We also make an attempt of applying Blaser and Manthey‚Äôs (2015) smoothed complexity framework in social choice contexts by proving that the framework categorizes an always-exponential-time brute force search algorithm as being smoothed poly-time, under a natural noise model based on the well-studied Mallows model in social choice and statistics. Overall, our results show that smoothed complexity analysis in computational social choice is a challenging and fruitful topic.},
	language = {en},
	number = {6},
	urldate = {2023-11-26},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Xia, Lirong and Zheng, Weiqiang},
	month = may,
	year = {2021},
	note = {Number: 6},
	keywords = {Social Choice / Voting},
	pages = {5742--5750},
	file = {Full Text PDF:files/708/Xia Âíå Zheng - 2021 - The Smoothed Complexity of Computing Kemeny and Sl.pdf:application/pdf},
}
